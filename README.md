<pre><code> 
 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 *                                       Copyright (c) 2025 syncUs (ShiftAPPens)                                   *
 *                                                                                                                 *
 *          This project and the accompanying materials are made available under the terms of the Eclipse          *
 *                  Public License 2.0 which is available at: http://www.eclipse.org/legal/epl-2.0                 *
 *                                                                                                                 *
 *                       Created during the ShiftHAPPens Hackathon, Coimbra 2025                                   *
 *                                                                                                                 *
 *                                         SPDX-License-Identifier: EPL-2.0                                        *
 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
</code></pre>

# üé∂ SyncBeat ‚Äî Move. Draw. Sound.

**Transform movement and drawing into music.**  
With **SyncBeat**, your camera becomes your instrument. Whether you're dancing in front of your screen or sketching on a tablet, every gesture creates sound ‚Äî from melodies to abstract soundscapes.

---

## üß© The Problem

Creating music and visual art traditionally requires:

- Specialized technical knowledge  
- Visual and motor skills  
- Complex interfaces  

These barriers exclude many people ‚Äî including children, individuals with visual impairments, or those with no musical/artistic background ‚Äî from fully engaging in creative expression.  
Moreover, there is a **lack of inclusive tools** that intuitively blend **movement, drawing, and sound** in a sensory-rich experience.

---

## üí° The Solution

**SyncBeat** is an interactive application that converts real-time **body movement** and **hand-drawn input** into sound.  
Using a **camera** (from a laptop or tablet), users can move or draw freely ‚Äî the application translates these gestures into dynamic compositions:

üéµ Notes  
üé® Textures  
üîä Soundscapes

### üß† Key Features

- Real-time gesture-to-sound transformation  
- Drawing-based musical input  
- Voice guidance & sound feedback for blind or low-vision users  
- Designed for **creativity**, **education**, **therapy**, and **art**

> A playful and inclusive way to explore the connection between **body**, **sound**, and **image**.

---

## üë• Team SyncUs

- **Catarina Pereira** ‚Äî M.Sc. in Telecommunications and Computer Engineering, University of Minho  
- **Daniel Cardoso** ‚Äî M.Sc. in Electronics and Computer Engineering, University of Minho  
- **Filipe Gaio** ‚Äî B.Sc. in Informatics Engineering, University of Porto  
- **Lic√≠nia Mendes** ‚Äî Physics Engineering, University of Minho  

---

üåê Built with passion during the **ShiftAPPens Hackathon 2025**, in Coimbra.  
üéß Let your creativity move you ‚Äî literally.




